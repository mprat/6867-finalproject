\documentclass[10pt]{article}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphicx}
% \usepackage{multirow}
% \usepackage{wrapfig}
\usepackage{enumerate}
\usepackage{cite}
% \usepackage[margin=1.1in]{geometry}

\begin{document}
\title{6.867 Final Project: Simple Versus Complex Neural Networks for Computer Vision Tasks}
\author{Michele Pratusevich}
\date{\today}
\maketitle

\begin{abstract}
Something here. Do I even need this?
\end{abstract}

\section{Introduction}

Collaboration between artificial intelligence, neuroscience, and machine learning resulted in the invention of neural networks for use in classification or prediction tasks. With roots from single-layer perceptrons \cite{rosenblatt_perceptron:_1958} to multi-layer and kernel perceptrons \cite{aizerman_theoretical_1964}, increasing success on non-linear classification tasks (especially related to vision or images) have seen the revival of their popularity among the computer vision community. 

A popular success story is the development of a back-propagation convolutional neural network (CNN) for handwritten digit recognition \cite{lecun_handwritten_1990}. The original data used was approximately 10,000 handwritten digits, classified into one of 10 categories (one category for each digit). This original dataset was later expanded into the MNIST handwritten digit database with over 60,000 examples \cite{lecun_gradient-based_1998}, \cite{li_deng_mnist_2012}. The network used by LeCunn et. al. used the idea of convolution layers - described essentially as features extracted from parts of the image by kernels of varying sizes, generally getting smaller and smaller. The general idea is that these $n \times n$ kernels will `find' specific features in the image. In between, there are layers that perform averaging or weighting of the features that it receives. The final layer is fully-connected to the receptive fields of the previous layer and outputs a probability estimate for the class the image belongs to, meaning it essentially performs a weighted sum of all the inputs it sees for each parameter, with different weight parameters for each predicted class. Improvements to this network have been made incrementally over time, but the error rates on the test set for this initial network was $3.7$ percent. 

The interesting insights from LeCun's simplified architecture \cite{lecun_handwritten_1990} compared to a previous network that had more connections (also designed by LeCun) \cite{lecun_backpropagation_1989} were two-fold: (1) that images could be fed directly into the neural network rather than extracting features, then feeding the features into the network, and (2) knowing a-priori the nature of the classification task can give hints about how to simplify the network to contain fewer parameters to optimize over. In general, these ideas of simplification of neural networks can be applied to larger and more complex neural networks \cite{lecun_optimal_1989}. 

Since LeCun's successful use of CNNs for handwritten digit classification, CNNs became a popular technique for completing computer vision tasks. Krizhevsky et. al. \cite{krizhevsky_imagenet_2012} constructed an 8-layer CNN that achieved 17 percent top-5 error rates on the ImageNet database \cite{russakovsky_imagenet_2014}, taking advantage of optimizations using GPUs and a few other numerical improvements cited in the paper. Since then, very deep CNNs have been used for nearly every computer vision task with a standard dataset, and countless other non-standardized tasks. Since the original AlexNet was published, fine-tunings of the original network, in addition to changes to the architecture, were performed with the hopes of creating a neural network that can be used as a generalized feature extractor for all kinds of image tasks \cite{donahue_decaf:_2014}. Software packages to facilitate this and the use of GPUs for speed-up were created \cite{jia_caffe:_2014}. 

One big problem with using these extremely deep CNNs for feature extraction, fine-tuning, and general image classification tasks is the time needed to train these networks. With GPU speedups and optimized code, this task is made easier, but it still takes approximately 3 days on a GPU to train on the entirety of the ImageNet database (6 million images). Fine-tuning for a specific task using a pre-trained network takes less time, but depending on the desired result takes a few hours. Another big problem with deep CNNs for vision tasks is the need for extremely large quantities of labeled training data. For a large network with 10000s of parameters, having only 50 labeled training images is not enough to optimize over. AlexNet was only able to train from scratch because the training set for ImageNet is incredibly large, with approximately 10,000 images per class and a total of 1000 classes. 

Training neural networks still requires the fine-tuning of hyperparameters dictating the learning rate and the weight decay, but some have offered suggestions for how to improve back-propagation and the choosing of hyperparameters \cite{bottou_large-scale_2010}. However, simultaneously, there have been a number of papers questioning the need for the depth and complexity of the recently-used CNNs \cite{ba_deep_2013}. LeCun provided suggestions for the simplification of neural networks when working with the original handwritten digit classification network \cite{lecun_optimal_1989}. Another interesting area of research has been the idea of using Gaussian processes to optimize parameters in a neural network for a specific task. 

In this project, I will explore the idea of simplified CNNs for the scene recognition vision task, drawing on ideas from recent literature about the effectiveness of using pre-trained networks, simplifying existing networks, and using extracted features to do various tasks. 

\section{Dataset and Tools}

The task of scene recognition is different from object recognition in that the classification requires 

% * CNNs have proven effective in image classification because of the ability to learn high-level features
% * CNN is like a multiclass perceptron?
% 	* start with a single multiclass logistic regression classifier in caffe on SUN
% * http://groups.csail.mit.edu/vision/SUN/
% * neural networks are really networks of logistic regression things
% * multiclass logistic regression on SUN database

% * can use the dataset that is already on aditya's folder: 
% /data/vision/torralba/aditya_datasets/data/SUN397/SUN397

% 1. simple logistic regression classifier: network example given here http://caffe.berkeleyvision.org/tutorial/net_layer_blob.html

\section{Method}

* had to install caffe
* mostly used resources online, except the built-in ATLAS on my OSX machine was not working, so had to add openblas to teh list of brew packages needed to be edited / installed / compiled

* learning rate of zero means that no learning is happening. 

optimization of hyperparameters is the hardest part. some tricks from \cite{bottou_large-scale_2010}.

\section{Experiments}

* Running with a 0 learning rate does give top-5 accuracy of 0.01
* got 14 percent accuracy with logistic regression

* max-pooling `localizes' an object? maybe this is not necessary when doing scene recognition

* need to also compare to fine-tuning places CNN to SUN397

\bibliographystyle{plain}
\bibliography{6867project}

\end{document}